{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVM/tHtr4ghdR9E72GmtfT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javad-Manashti/Airport-Traffic-Analysis-and-Flight-Sequence-Tracking-Using-PySpark/blob/main/Airport_Traffic_Analysis_and_Flight_Sequence_Tracking_Using_PySpark_(Advanced).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Airport Traffic Analysis and Flight Sequence Tracking Using PySpark (Advanced)\n",
        "\n",
        "**By: Javad Manashty (5146323306, mjmanashti@gmial.com)**\n",
        "\n",
        "#### Description:\n",
        "This enhanced PySpark code offers a professional solution for analyzing airport traffic and tracking flight sequences. It processes large datasets to deliver insights into flight scheduling and airport operations. The code is divided into two primary sections:\n",
        "\n",
        "1. **Flight Sequence Tracking**: It determines the sequence of flights for each aircraft by identifying subsequent flights. This feature aids in understanding aircraft utilization and turnover, crucial for scheduling and operational efficiency.\n",
        "\n",
        "2. **Airport Traffic Analysis**: This part of the script calculates the number of inbound and outbound flights at an airport in 15-minute intervals. Such granular data analysis is vital for comprehending traffic patterns, leading to better resource allocation and strategic planning at airports.\n",
        "\n",
        "The script is adept at handling datasets with details such as flight origin, destination, and timings, leveraging PySpark's robust data processing features.\n",
        "\n",
        "#### Key Components of the Code:\n",
        "- **Initialization of Spark Session**: Establishes the Spark environment for data processing.\n",
        "- **Data Ingestion and Preparation**: Efficiently reads flight data from a CSV file into a Spark DataFrame, converting timestamps into a suitable format for analysis.\n",
        "- **Construction of Flight Sequences**: Implements window functions to organize data chronologically for each aircraft, identifying the next flight in the sequence.\n",
        "- **Airport Traffic Dataset Creation**: Aggregates data into 15-minute intervals to compute inbound and outbound flight counts, offering a comprehensive overview of airport traffic.\n",
        "- **Structured Output Presentation**: Displays results methodically, showing both the sequence of flights for each aircraft and the detailed airport traffic data.\n",
        "\n",
        "#### Output Verification:\n",
        "The output is carefully presented alongside the code to verify its accuracy and effectiveness. It includes:\n",
        "- A sequence table for each aircraft, detailing flight ID, registration code, arrival time, and the subsequent flight ID.\n",
        "- An exhaustive table illustrating the count of inbound and outbound flights in each 15-minute interval at selected airports.\n",
        "\n",
        "This comprehensive code, along with its outputs, stands as proof of a functional solution, exemplifying the capability to analyze flight data proficiently using PySpark.\n",
        "\n",
        "#### Considerations for Further Improvement:\n",
        "While the script is robust and professional, there are areas for further enhancement:\n",
        "- **Unit Testing**: Incorporating a framework like PyTest for unit testing each function would substantially increase code reliability.\n",
        "- **Advanced Error Handling**: Implementing more sophisticated error handling and logging mechanisms for improved debugging and maintenance.\n",
        "- **Configurability**: Adding a configuration file for parameters like file paths and database connections could enhance the script's flexibility and adaptability for different environments or datasets.\n",
        "- **Performance Optimization**: Depending on dataset size, implementing strategies like broadcast joins or caching could optimize performance.\n",
        "- **Documentation and Commenting**: Expanding the documentation and inline commenting to cover more complex logic and optimizations, facilitating better understanding for future maintenance or enhancements.\n",
        "\n",
        "These improvements would elevate the script's professionalism, making it even more suitable for complex, real-world data engineering scenarios."
      ],
      "metadata": {
        "id": "xqoygWwC5ILg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Setting Up PySpark for Data Processing**\n",
        "\n",
        "   This code segment provides instructions for installing and initializing PySpark, an essential component for efficient data processing. It sets the foundation for Spark-based data manipulation and analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "X9vhqQSy5kSN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "abIksRWyvd7E"
      },
      "outputs": [],
      "source": [
        "# Installing and Initializing PySpark\n",
        "\"\"\"\n",
        "This code segment provides instructions for installing and initializing PySpark, a powerful tool for distributed data processing. PySpark is a fundamental component for conducting data analysis and processing at scale.\n",
        "\"\"\"\n",
        "\n",
        "# Install PySpark using pip\n",
        "!pip install pyspark\n",
        "\n",
        "# Import the necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize a Spark session with a meaningful application name\n",
        "spark = SparkSession.builder.appName(\"SPARKProcessing\").getOrCreate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Flight Data Analysis and Airport Traffic Evaluation**\n",
        "\n",
        "   This section of the code showcases the core functionality of tracking flight sequences and analyzing airport traffic using PySpark. It demonstrates how to process and analyze aviation data, making it a valuable tool for aviation and airport management."
      ],
      "metadata": {
        "id": "XD2f6KvZ5l2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, window, lead, date_format\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import TimestampType\n",
        "\n",
        "def initialize_spark_session(app_name):\n",
        "    \"\"\"Initialize and return a Spark session.\"\"\"\n",
        "    return SparkSession.builder.appName(app_name).getOrCreate()\n",
        "\n",
        "def read_csv_to_df(spark, file_path, timestamp_cols):\n",
        "    \"\"\"Read a CSV file into a Spark DataFrame and process timestamp columns.\"\"\"\n",
        "    try:\n",
        "        df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "        for col_name in timestamp_cols:\n",
        "            df = df.withColumn(col_name, col(col_name).cast(TimestampType()))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the CSV file: {e}\")\n",
        "        return None\n",
        "\n",
        "def build_flight_sequence(df):\n",
        "    \"\"\"Build and return a DataFrame with flight sequence information.\"\"\"\n",
        "    window_spec = Window.partitionBy(\"acft_regs_cde\").orderBy(\"actl_arr_lcl_tms\")\n",
        "    return df.withColumn(\"next_flight_id\", lead(\"id\", 1).over(window_spec))\n",
        "\n",
        "def analyze_airport_traffic(df):\n",
        "    \"\"\"Analyze and return airport traffic data.\"\"\"\n",
        "    try:\n",
        "        inbound_traffic = df.groupBy(\"orig\", window(col(\"actl_arr_lcl_tms\"), \"15 minutes\")).count().withColumnRenamed(\"count\", \"in\").withColumnRenamed(\"orig\", \"airport_code\")\n",
        "        outbound_traffic = df.groupBy(\"dest\", window(col(\"actl_dep_lcl_tms\"), \"15 minutes\")).count().withColumnRenamed(\"count\", \"out\").withColumnRenamed(\"dest\", \"airport_code\")\n",
        "        airport_traffic = inbound_traffic.join(outbound_traffic, [\"window\", \"airport_code\"], \"outer\")\n",
        "        return airport_traffic.select(col(\"airport_code\"), date_format(col(\"window\").start, \"yyyy-MM-dd'T'HH:mm:ss\").alias(\"tms\"), \"out\", \"in\").na.fill(value=0, subset=[\"in\", \"out\"])\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing airport traffic: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    app_name = \"FlightDataAnalysis\"\n",
        "    csv_file_path = '/content/Data Engineer exercise.csv'  # This can be parameterized as needed\n",
        "    timestamp_cols = ['actl_dep_lcl_tms', 'actl_arr_lcl_tms', 'airborne_lcl_tms', 'landing_lcl_tms']\n",
        "\n",
        "    # Initialize Spark session\n",
        "    spark = initialize_spark_session(app_name)\n",
        "\n",
        "    # Read data and prepare DataFrame\n",
        "    spark_df = read_csv_to_df(spark, csv_file_path, timestamp_cols)\n",
        "    if spark_df is not None:\n",
        "        # Build a String of Flights\n",
        "        flight_sequence_df = build_flight_sequence(spark_df)\n",
        "\n",
        "        # Build a Dataset for Airport Traffic\n",
        "        airport_traffic_df = analyze_airport_traffic(spark_df)\n",
        "\n",
        "        if airport_traffic_df is not None:\n",
        "            # Show results\n",
        "            flight_sequence_df.show(5)\n",
        "            airport_traffic_df.orderBy(\"airport_code\", \"tms\").show(50)\n",
        "\n",
        "    # Stopping the Spark session\n",
        "    spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ6OWbJlvfwb",
        "outputId": "99360f65-3bdb-435b-c717-6bec2dda0c6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---+-------------------+-------------------+----------+-------+-------------+-------------------+-------------------+--------------+\n",
            "|orig|dest| id|   actl_dep_lcl_tms|   actl_arr_lcl_tms|flight_num|flights|acft_regs_cde|   airborne_lcl_tms|    landing_lcl_tms|next_flight_id|\n",
            "+----+----+---+-------------------+-------------------+----------+-------+-------------+-------------------+-------------------+--------------+\n",
            "| YVR| YYZ| 21|2022-12-31 00:29:00|2022-12-31 08:27:00|       128|      1|          451|2022-12-31 01:01:00|2022-12-31 08:11:00|            10|\n",
            "| YYZ| YVR| 10|2022-12-31 08:50:00|2022-12-31 10:38:00|       103|      1|          451|2022-12-31 09:13:00|2022-12-31 10:28:00|            16|\n",
            "| YVR| YYZ| 16|2022-12-31 11:55:00|2022-12-31 19:10:00|       106|      1|          451|2022-12-31 12:10:00|2022-12-31 18:55:00|             2|\n",
            "| YYZ| YVR|  2|2022-12-31 19:39:00|2022-12-31 21:22:00|       185|      1|          451|2022-12-31 20:05:00|2022-12-31 21:14:00|          NULL|\n",
            "| YYZ| YVR|  9|2022-12-31 10:18:00|2022-12-31 12:27:00|       107|      1|          457|2022-12-31 10:39:00|2022-12-31 12:08:00|            14|\n",
            "+----+----+---+-------------------+-------------------+----------+-------+-------------+-------------------+-------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+-------------------+---+---+\n",
            "|airport_code|                tms|out| in|\n",
            "+------------+-------------------+---+---+\n",
            "|         YVR|2022-12-31T08:15:00|  0|  1|\n",
            "|         YVR|2022-12-31T08:45:00|  1|  0|\n",
            "|         YVR|2022-12-31T10:15:00|  1|  0|\n",
            "|         YVR|2022-12-31T11:15:00|  1|  0|\n",
            "|         YVR|2022-12-31T13:00:00|  1|  0|\n",
            "|         YVR|2022-12-31T13:15:00|  0|  1|\n",
            "|         YVR|2022-12-31T14:30:00|  1|  0|\n",
            "|         YVR|2022-12-31T15:15:00|  0|  1|\n",
            "|         YVR|2022-12-31T16:30:00|  1|  0|\n",
            "|         YVR|2022-12-31T16:45:00|  0|  1|\n",
            "|         YVR|2022-12-31T17:15:00|  1|  1|\n",
            "|         YVR|2022-12-31T18:45:00|  1|  0|\n",
            "|         YVR|2022-12-31T19:00:00|  0|  1|\n",
            "|         YVR|2022-12-31T19:30:00|  1|  0|\n",
            "|         YVR|2022-12-31T19:45:00|  0|  1|\n",
            "|         YVR|2022-12-31T20:30:00|  1|  0|\n",
            "|         YVR|2022-12-31T21:15:00|  0|  1|\n",
            "|         YVR|2022-12-31T22:15:00|  0|  1|\n",
            "|         YVR|2022-12-31T23:15:00|  0|  1|\n",
            "|         YYZ|2022-12-31T00:15:00|  1|  0|\n",
            "|         YYZ|2022-12-31T06:00:00|  1|  0|\n",
            "|         YYZ|2022-12-31T08:00:00|  1|  0|\n",
            "|         YYZ|2022-12-31T09:45:00|  1|  0|\n",
            "|         YYZ|2022-12-31T10:00:00|  1|  0|\n",
            "|         YYZ|2022-12-31T10:30:00|  0|  1|\n",
            "|         YYZ|2022-12-31T11:45:00|  1|  0|\n",
            "|         YYZ|2022-12-31T12:15:00|  0|  1|\n",
            "|         YYZ|2022-12-31T12:45:00|  1|  0|\n",
            "|         YYZ|2022-12-31T13:00:00|  0|  1|\n",
            "|         YYZ|2022-12-31T14:00:00|  1|  0|\n",
            "|         YYZ|2022-12-31T14:45:00|  1|  1|\n",
            "|         YYZ|2022-12-31T16:00:00|  1|  0|\n",
            "|         YYZ|2022-12-31T16:30:00|  0|  1|\n",
            "|         YYZ|2022-12-31T18:30:00|  0|  1|\n",
            "|         YYZ|2022-12-31T19:00:00|  0|  1|\n",
            "|         YYZ|2022-12-31T20:30:00|  0|  1|\n",
            "|         YYZ|2022-12-31T21:15:00|  0|  1|\n",
            "|         YYZ|2022-12-31T22:15:00|  0|  1|\n",
            "+------------+-------------------+---+---+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
